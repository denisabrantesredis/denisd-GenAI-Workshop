{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AkZOYLVbc6m"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Redislabs-Solution-Architects/Redis-Workshops/blob/main/04-Large_Language_Model/04.02_Large_Language_Model_Google.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Large Language Models\n",
        "\n",
        "![Redis](https://redis.io/wp-content/uploads/2024/04/Logotype.svg?auto=webp&quality=85,75&width=120)\n",
        "\n",
        "In this notebook you'll be sending prompts to LLMs programatically. Google's `gemini-pro` and (optionally) self-hosted in-notebook `databricks/dolly-v2`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBmXNV2Qpkhe",
        "outputId": "aaf1f9d5-88ac-4913-8c36-b0f809cca603"
      },
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip -q install google-generativeai accelerate transformers sentence-transformers tiktoken"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUa-ZQkNchnc"
      },
      "source": [
        "## Authenticate notebook to Google Cloud API\n",
        "You can get your Google Cloud API key at https://console.cloud.google.com/apis/credentials\n",
        "\n",
        "For security reason we recomment to restrict the key to allow only Generative Language API\n",
        "\n",
        "***Note - If you are participating in a workshop, your instructor should provide you with an API key.***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8R4COiD08Ux",
        "outputId": "dd149005-b4f0-4bfa-dc04-289febcd87b2"
      },
      "outputs": [],
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "if \"GOOGLE_API_KEY\" not in os.environ:\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Provide your Google API Key: \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhlFMsm88r0u"
      },
      "source": [
        "Test that we have access to Google APIs by requesting the list of models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZsHU_3zD8Tzi",
        "outputId": "7c62fdb8-88a6-438b-c033-512be2947fa0"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "for m in genai.list_models():\n",
        "  if 'generateContent' in m.supported_generation_methods:\n",
        "    print(m.name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-lVNefzcxRq"
      },
      "source": [
        "***Note - This step is optional. Uncomment and run this cell if you do not have a Google Cloud API key or would like to compare results from Gemini and a self-hosted model***\n",
        "\n",
        "Initialize `databricks/dolly-v2-3b` via [HuggingFace](https://huggingface.co/databricks/dolly-v2-3b). Multiple progressively more powerful models are available, including 3b, 7b and 12b (referring to Billions of parameters). `dolly-v2-3b` is the only model in the family that would fit in the memory and GPU available in a free Google Colab instance.\n",
        "\n",
        "Loading and initializing the model can take few minutes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "wBZG4fmnpoiR",
        "outputId": "393d624c-d8a7-418e-a6ae-40cde51f0524"
      },
      "outputs": [],
      "source": [
        "# Skip dolly initialization\n",
        "# import torch\n",
        "# from transformers import pipeline\n",
        "\n",
        "# dolly_completion = pipeline(model=\"databricks/dolly-v2-3b\",\n",
        "#                          torch_dtype=torch.bfloat16,\n",
        "#                          trust_remote_code=True,\n",
        "#                          device_map=\"auto\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4kBXv65d2Sj"
      },
      "source": [
        "Helper function for Google Gemini model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "73GvlwaM07b-"
      },
      "outputs": [],
      "source": [
        "model = genai.GenerativeModel('gemini-pro')\n",
        "def gemini_completion(prompt):\n",
        "    response = model.generate_content(prompt)\n",
        "    return response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAY1sbW-d3os"
      },
      "source": [
        "# Create the prompt\n",
        "\n",
        "Prompt contains instructions, context and the question. Feel free to experiment with the prompt and see the difference in responses from different models.\n",
        "\n",
        "News article used in this example: https://techcrunch.com/2023/10/31/toyota-to-invest-another-8b-into-north-carolina-ev-battery-factory/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwO9x-kypsst",
        "outputId": "daa5e2b9-49ae-410c-bb0f-7980e65fbf59"
      },
      "outputs": [],
      "source": [
        "# Specify the content, question, and propmt to be passed to the LLM\n",
        "context = \"\"\"\n",
        "Toyota said Tuesday it will invest another $8 billion into its first EV battery factory in North America, as the Japanese automaker tries to ramp up its electrification program and introduce 30 battery electric models globally by the end of the decade.\n",
        "The North Carolina-based factory, which is slated to go into production in 2025, is now valued at $13.9 billion, according to the company. \n",
        "That’s a jump from Toyota’s initial plans to make a $1.29 billion investment to build a North American factory that will make batteries for hybrid electric vehicles and battery electric vehicles.\n",
        "This latest investment will add eight battery electric and plug-in hybrid battery production lines to the facility located on 1,825 acres in Liberty, North Carolina. \n",
        "Once completed, the factory will have 10 lines and will reach a total production capacity of 30 GWh annually by 2030. To put that into perspective, the so-called Tesla gigafactory, which is a joint venture between the automaker and Panasonic, has the capacity to make 35 GWh of cells annually.\n",
        "\"\"\"\n",
        "\n",
        "question = \"What is Toyota building in North Carolina?\"\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Instruction: Use only information in the following context to answer the question at the end.\n",
        "If you don't know, say that you do not know.\n",
        "\n",
        "Context:  {context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Response:\n",
        "\"\"\"\n",
        "\n",
        "print(prompt)\n",
        "\n",
        "res = gemini_completion(prompt)\n",
        "print(\"\\nGemini:\")\n",
        "print(res.candidates[0].content.parts[0].text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBEIzCOCZUBB"
      },
      "source": [
        "## TODO:\n",
        "Play around with basic prompts to see what kind of replies you can generate.\n",
        "\n",
        "Some ideas for you to try:\n",
        "- Add \"Respond in French/Spanish\" to the prompt.\n",
        "\n",
        "- Add more information into the context until you hit the token limit of the model.\n",
        "\n",
        "- Check system memory: e.g. \"What was my last question?\"\n",
        "\n",
        "- Provoke hallucinations, e.g. \"What was the name of the first elephant to walk on the moon?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWnI5NVkfa8L",
        "outputId": "609f62e5-04a8-44d5-9c68-18681fb7f54f"
      },
      "outputs": [],
      "source": [
        "prompt = \"Tell me about Dallas, Texas\"\n",
        "\n",
        "# Uncomment if you installed the dolly model locally and would like to compare results\n",
        "# res = dolly_completion(prompt)\n",
        "# print(\"Dolly:\")\n",
        "# print(res[0]['generated_text'])\n",
        "\n",
        "res = gemini_completion(prompt)\n",
        "print(\"\\nGemini:\")\n",
        "print(res.candidates[0].content.parts[0].text)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
