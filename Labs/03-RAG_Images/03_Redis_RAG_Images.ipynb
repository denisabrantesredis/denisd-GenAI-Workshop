{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N09X5wKjBIsT"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/denisabrantesredis/denisd-GenAI-Workshop/blob/main/Labs/03-RAG_Images/03_Redis_RAG_Images.ipynb\" target=\"_newt\">\n",
        "<img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Tk5ymdLBTeq"
      },
      "source": [
        "<div style=\"display:flex;width=100%;\">\n",
        "<img src=\"https://redis.io/wp-content/uploads/2024/04/Logotype.svg?auto=webp&quality=85,75&width=120\" alt=\"Redis\" width=\"90\"/>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
        "<img src=\"https://www.gstatic.com/devrel-devsite/prod/v0e0f589edd85502a40d78d7d0825db8ea5ef3b99ab4070381ee86977c9168730/cloud/images/cloud-logo.svg\" alt=\"Google Cloud\" width=\"140\"/>\n",
        "</div>\n",
        "\n",
        "# Vector Similarity Search with Redis & Google Cloud - RAG for Images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWGXHwYEOZoT"
      },
      "source": [
        "<img src=\"https://github.com/denisabrantesredis/denisd-GenAI-Workshop/blob/main/_assets/images/redis_gcp.png?raw=true\" alt=\"Redis and Google Cloud\" align=\"center\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8w5OAHNOlFf"
      },
      "source": [
        "[Try a similar app with an always-on demo](https://ecommerce.redisventures.com/)\n",
        "\n",
        "In this notebook, we will build a RAG use case using data from a web page. Redis will be used as the Vector Database and Cache for our use case, while Google Gemini is the LLM that will help generate the answers to the user's questions.\n",
        "\n",
        "The dataset for this lab contains images of products like shoes, watches, clothes, etc. We will use Google Gemini to provide a description of each product that we can use as metadata."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENspmGoTR6tq"
      },
      "source": [
        "## Installing the Pre-Reqs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WFmBBQ0bBFym"
      },
      "outputs": [],
      "source": [
        "!pip install -q sentence-transformers==3.0.1 >> /.tmp\n",
        "!pip install -q redis==5.0.8 >> /.tmp\n",
        "!pip install -q redisvl==0.3.5 >> /.tmp\n",
        "!pip install -q langchain==0.2.16 >> /.tmp\n",
        "!pip install -q langchain-core==0.3.6 >> /.tmp\n",
        "!pip install -q langchain-huggingface==0.0.3 >> /.tmp\n",
        "!pip install -q langchain-redis==0.0.4 >> /.tmp\n",
        "!pip install -q langchain-google-genai==2.0.0 >> /.tmp\n",
        "!pip install -q langchain_experimental==0.3.2 >> /.tmp\n",
        "!pip install -q open-clip-torch==2.26.1 >> /.tmp\n",
        "!pip install -q git+https://github.com/openai/CLIP.git >> /.tmp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# patch an issue with RedisVL\n",
        "!wget https://github.com/denisabrantesredis/denisd-GenAI-Workshop/raw/refs/heads/main/_assets/files/semantic.py\n",
        "!rm /usr/local/lib/python3.10/dist-packages/redisvl/extensions/llmcache/semantic.py\n",
        "!cp semantic.py /usr/local/lib/python3.10/dist-packages/redisvl/extensions/llmcache/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Installing Redis Stack Locally\n",
        "If you are not using Redis Cloud as a database, uncomment and run the code below to install Redis locally. Then set your connection to 127.0.0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %%sh\n",
        "# curl -fsSL https://packages.redis.io/gpg | sudo gpg --dearmor -o /usr/share/keyrings/redis-archive-keyring.gpg \n",
        "# echo \"deb [signed-by=/usr/share/keyrings/redis-archive-keyring.gpg] https://packages.redis.io/deb $(lsb_release -cs) main\" | sudo tee /etc/apt/sources.list.d/redis.list \n",
        "# sudo apt-get update  > /dev/null 2>&1\n",
        "# sudo apt-get install redis-stack-server  > /dev/null 2>&1\n",
        "# redis-stack-server --daemonize yes "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQ6RwklAct5K"
      },
      "source": [
        "### Loading Required Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Ko4lH56BFs3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import json\n",
        "import redis\n",
        "import torch\n",
        "import base64\n",
        "import random\n",
        "from typing import Any, Dict\n",
        "from IPython.display import Image\n",
        "from google.colab import userdata\n",
        "from langchain_core.messages import HumanMessage\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from pydantic import BaseModel, Field, model_serializer\n",
        "from langchain.output_parsers import PydanticOutputParser\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8Cq6TN1DrIk"
      },
      "source": [
        "## Part 1 - Prepare the Environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7QXZVQSDxlm"
      },
      "source": [
        "### Step 1: Download Dataset from Github"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33RhGtaaduow"
      },
      "source": [
        "For performance reasons, we will only be working with 20 images. In this github repo, you can find a zip file with 100 images that can be used instead, if you want to test this code in an environment with more resources, like Google Vertex AI.\n",
        "\n",
        "We will download the images that will be stored in Redis as vectors, as well as a smaller dataset of images that will be used for semantic search."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NHd7FtUPBFlE"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists(\"./img_20\"):\n",
        "  !wget https://github.com/denisabrantesredis/denisd-GenAI-Workshop/raw/refs/heads/main/_assets/files/img20.zip\n",
        "  !unzip img20.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jvoJfpupBFf2"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists(\"./img_search_20\"):\n",
        "  !wget https://github.com/denisabrantesredis/denisd-GenAI-Workshop/raw/refs/heads/main/_assets/files/img_search20.zip\n",
        "  !unzip img_search20.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQkY7YrLkUZD"
      },
      "source": [
        "### Step 2: Setting up the Redis connection and GCP API Key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfApethtkegP"
      },
      "source": [
        "<img src=\"https://github.com/denisabrantesredis/denisd-GenAI-Workshop/blob/main/_assets/images/callout_secrets.png?raw=true\" alt=\"Callout - Use Google Colab secrets instead\"/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yTHiBGT_GYac"
      },
      "outputs": [],
      "source": [
        "if \"GOOGLE_API_KEY\" not in os.environ:\n",
        "    if userdata.get('GOOGLE_API_KEY'):\n",
        "      os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GOOGLE_API_KEY')\n",
        "    else:\n",
        "      os.environ[\"GOOGLE_API_KEY\"] = \"<insert API key here>\"\n",
        "\n",
        "if userdata.get('REDIS_HOST'):\n",
        "  REDIS_HOST = userdata.get('REDIS_HOST')\n",
        "else:\n",
        "  REDIS_HOST=\"127.0.0.1\"\n",
        "\n",
        "if userdata.get('REDIS_PORT'):\n",
        "  REDIS_PORT = userdata.get('REDIS_PORT')\n",
        "else:\n",
        "  REDIS_PORT=12000\n",
        "\n",
        "if userdata.get('REDIS_PASSWORD'):\n",
        "  REDIS_PASSWORD = userdata.get('REDIS_PASSWORD')\n",
        "else:\n",
        "  REDIS_PASSWORD=\"password\"\n",
        "\n",
        "REDIS_URL = f\"redis://default:{REDIS_PASSWORD}@{REDIS_HOST}:{REDIS_PORT}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKgHfuHnlcXh"
      },
      "source": [
        "#### Testing the Connection to Redis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nmj6JoY0letv"
      },
      "source": [
        "<img src=\"https://github.com/denisabrantesredis/denisd-GenAI-Workshop/blob/main/_assets/images/callout_connection.png?raw=true\" alt=\"Callout - Make sure connection works\"/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tMAp-8M-j8yo"
      },
      "outputs": [],
      "source": [
        "r = redis.from_url(REDIS_URL)\n",
        "\n",
        "if r.ping():\n",
        "    print(\"Connection successful!\")\n",
        "else:\n",
        "    print(\"Connection issue!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvIQKclfl-3S"
      },
      "source": [
        "### Step 3: Load the list of images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This lab can greatly benefit from running on a T4 GPU. However, seeing as GPUs are not guaranteed in the free tier, the lab was designed to also run on CPUs, albeit slower."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FCjcJIrsGlqI"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C0H9huxKHI4q"
      },
      "outputs": [],
      "source": [
        "filenames = glob.glob(\"./img_20/*\")\n",
        "len(filenames)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Step 4: Load Gemini and get it to describe an image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-flash\",\n",
        "    temperature=0.5,\n",
        "    top_p=0.95,\n",
        "    top_k=64,\n",
        "    max_output_tokens=8192\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Display the image that will be sent to the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(filenames[0], \"rb\") as image_file:\n",
        "    image_data = base64.b64encode(image_file.read()).decode()\n",
        "\n",
        "Image(filenames[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6Y3Fy_JnSm5"
      },
      "source": [
        "<img src=\"https://github.com/denisabrantesredis/denisd-GenAI-Workshop/blob/main/_assets/images/callout_geminiimage.png?raw=true\" alt=\"Callout - Upload Image to Gemini\"/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VLUdjv5KHOpJ"
      },
      "outputs": [],
      "source": [
        "message = HumanMessage(\n",
        "    content=[\n",
        "        {\"type\": \"text\", \"text\": \"describe the object in this image\"},\n",
        "        {\n",
        "            \"type\": \"image_url\",\n",
        "            \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_data}\"},\n",
        "        },\n",
        "    ],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_j8oVZIzgvv"
      },
      "source": [
        "Call the model and print the response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9g-MMhPNze4Z"
      },
      "outputs": [],
      "source": [
        "# Invoke the model with the message\n",
        "response = llm.invoke([message])\n",
        "\n",
        "# Print the model's response\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jHy0dVgsAAg"
      },
      "source": [
        "&nbsp;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__zfLJoaHa13"
      },
      "source": [
        "## Part 2: Categorizing the Images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sjpqcmh8vGFP"
      },
      "source": [
        "Usually, a dataset of images would have a curated set of metadata attributes, that would be used as metadata for hybrid searches. In this lab, however, we will generate metadata for each image using Google Gemini to provide a description of the image and its key characteristics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hS3kewVQvR8y"
      },
      "source": [
        "### Prepare a list of images on base64 format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-n9ER0lHi12"
      },
      "outputs": [],
      "source": [
        "image_list = []\n",
        "for i in range(len(filenames)):\n",
        "    this_image_path = filenames[i]\n",
        "    with open(this_image_path, \"rb\") as image_file:\n",
        "        image_data = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
        "        image_list.append(image_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FKaU45iwULg"
      },
      "source": [
        "### Define a Pydantic class to parse the model's output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wepEg9G0umFH"
      },
      "outputs": [],
      "source": [
        "class Product(BaseModel):\n",
        "    name: str = Field(description=\"The name of the product shown in the image\")\n",
        "    color: str = Field(description=\"The color of the product shown in the image\")\n",
        "    type: str = Field(description=\"The type of product shown in the image\")\n",
        "    marketing_description: str = Field(description=\"A marketing description of the product shown in the image\")\n",
        "\n",
        "    @model_serializer(when_used='json')\n",
        "    def sort_model(self) -> Dict[str, Any]:\n",
        "        return dict(sorted(self.model_dump().items()))\n",
        "\n",
        "parser = PydanticOutputParser(pydantic_object=Product)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To prevent the model from generating similar descriptions for the products, we will command it to start the response with a certain letter each time. This will force the model to produce different descriptions. Do keep in mind that this is a very basic approach, for lab purposes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_random_letter():\n",
        "    letters = ['A', 'B', 'C', 'D', 'M', 'P', 'R', 'S', 'T']\n",
        "    return str(random.choice(letters))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Prepare the prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"Return the requested response object in {language}. Make sure the marketing description starts with the letter '{starting_letter}'\\n'{format_instructions}'\\n\"),\n",
        "    (\"human\", [\n",
        "        {\n",
        "            \"type\": \"image_url\",\n",
        "            \"image_url\": {\"url\": \"data:image/jpeg;base64,{image_data}\"},\n",
        "        },\n",
        "    ]),\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Configure the list of image descriptions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_images = [{\"language\": \"English\",\n",
        "               \"format_instructions\": parser.get_format_instructions(),\n",
        "               \"image_data\": image,\n",
        "               \"starting_letter\": generate_random_letter()}\n",
        "              for image in image_list]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create a chain and run it in parallel to speed up the creation of metadata using Google Gemini"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "chain = prompt | llm | parser\n",
        "results = chain.batch(all_images, config={\"max_concurrency\": 5})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Print the results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in range(20):\n",
        "    print(results[i].model_dump_json())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "&nbsp;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UALXxSxHHugw"
      },
      "source": [
        "## Part 3: Generate Image Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qC3h0h55yKKJ"
      },
      "source": [
        "To generate the image embeddings, we will use the CLIP model from OpenAI."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3UgzWI31G6P"
      },
      "source": [
        "### Step 1: Load the Embedding Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sAMSsoWgHw2u"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "from langchain_experimental.open_clip import OpenCLIPEmbeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This can take several minutes, as the model needs to be downloaded. Also, keep an eye on the memory usage for your notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NDNxn4XlIc6T"
      },
      "outputs": [],
      "source": [
        "clip_embd = OpenCLIPEmbeddings(model_name=\"ViT-g-14\", checkpoint=\"laion2b_s34b_b88k\", weights_only=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dazMdtlQIi6Z"
      },
      "source": [
        "### Step 2: Generate embeddings for all images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODF9JrNwz7Pu"
      },
      "source": [
        "First, we create a test embedding to make sure the model is working properly. The embedding should be an array with 1024 elements."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vptTC1f8Imo7"
      },
      "outputs": [],
      "source": [
        "embedding = clip_embd.embed_image([filenames[0]])\n",
        "len(embedding[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnQaXkij0GsC"
      },
      "source": [
        "Assuming the previous test was successful, generate embeddings for all 20 images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EJ0cxZ3AIpax"
      },
      "outputs": [],
      "source": [
        "counter = 0\n",
        "embeddings = []\n",
        "for filename in filenames:\n",
        "  print(f\"{counter} --> Generating embedding for file {filename}\")\n",
        "  embedding = clip_embd.embed_image([filename])\n",
        "  embeddings.append(embedding[0])\n",
        "  counter += 1\n",
        "len(embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wyvpWAdIscB"
      },
      "source": [
        "### Step 3: Visualize Images and Metadata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBeR4rv80Qhr"
      },
      "source": [
        "Before storing the images in Redis, we should see if the model was able to generate proper descriptions and metadata."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3HJjxxOcIuGy"
      },
      "outputs": [],
      "source": [
        "import IPython.display\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WaezsB6k0zxv"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20, 5))\n",
        "for i in range(20):\n",
        "    image_path = filenames[i]\n",
        "\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "    plt.subplot(4, 5, i+1)\n",
        "    plt.imshow(image)\n",
        "    label = f\"{image_path}\\n{results[i].name}\\n{results[i].type}\\n{results[i].color}\"\n",
        "    plt.xlabel(label, fontsize=8)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FtObK5_Iwmq"
      },
      "source": [
        "### Step 4: Prepare JSON documents for Redis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQjHLVPk5tL7"
      },
      "source": [
        "We need to format the data we want to store in Redis, by creating JSON documents that contain the embeddings and the metadata for each image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1QpDbPJCIzGE"
      },
      "outputs": [],
      "source": [
        "counter = 0\n",
        "vector_documents = []\n",
        "for embedding in embeddings:\n",
        "    vector_doc = json.loads(results[counter].model_dump_json())\n",
        "    vector_doc[\"id\"] = f\"vecdoc:{counter+1:05}\"\n",
        "    vector_doc[\"filename\"] = filenames[counter]\n",
        "    vector_doc[\"vector\"] = embedding\n",
        "    vector_documents.append(vector_doc)\n",
        "    counter = counter + 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZjMFpOF1AOY"
      },
      "source": [
        "Print an example document (truncating the vector to show only 5 elements)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DeCGJit20POh"
      },
      "outputs": [],
      "source": [
        "print(f\"ID: {vector_documents[0]['id']}\")\n",
        "print(f\"Name: {vector_documents[0]['name']}\")\n",
        "print(f\"Filename: {vector_documents[0]['filename']}\")\n",
        "print(f\"Type: {vector_documents[0]['type']}\")\n",
        "print(f\"Color: {vector_documents[0]['color']}\")\n",
        "print(f\"Description: {vector_documents[0]['marketing_description']}\")\n",
        "print(f\"{vector_documents[0]['vector'][:5]}...\")\n",
        "print(len(vector_documents[0]['vector']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KX9qkKbB526_"
      },
      "source": [
        "&nbsp;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xh-IMpo8JdB7"
      },
      "source": [
        "## Part 4: Storing data in Redis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFYrtKhb55KA"
      },
      "source": [
        "### Support Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R4kBM-GDJg4h"
      },
      "outputs": [],
      "source": [
        "import redis\n",
        "from redis.commands.json.path import Path\n",
        "from redis.commands.search.query import Query\n",
        "from redis.commands.search.indexDefinition import IndexDefinition, IndexType\n",
        "from redis.commands.search.field import NumericField, TagField, TextField, VectorField"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will manually create the search index, in order to understand the code that would be required without the Langchain automation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LtWde9w_J0sQ"
      },
      "outputs": [],
      "source": [
        "def create_index(VECTOR_DIMENSION):\n",
        "    result = \"FAILED\"\n",
        "    schema = (\n",
        "        TextField(\"$.id\", as_name=\"id\"),\n",
        "        TextField(\"$.name\", as_name=\"name\"),\n",
        "        TextField(\"$.filename\", as_name=\"filename\"),\n",
        "        TextField(\"$.type\", as_name=\"type\"),\n",
        "        TextField(\"$.color\", as_name=\"color\"),\n",
        "        TextField(\"$.marketing_description\", as_name=\"marketing_description\"),\n",
        "        VectorField(\n",
        "            \"$.vector\",\n",
        "            \"FLAT\",\n",
        "            {\n",
        "                \"TYPE\": \"FLOAT32\",\n",
        "                \"DIM\": VECTOR_DIMENSION,\n",
        "                \"DISTANCE_METRIC\": \"COSINE\",\n",
        "            },\n",
        "            as_name=\"vector\",\n",
        "        )\n",
        "    )\n",
        "    try:\n",
        "        definition = IndexDefinition(prefix=[\"vecdoc:\"], index_type=IndexType.JSON)\n",
        "        result = r.ft(\"idx:vecdoc\").create_index(fields=schema, definition=definition)\n",
        "    except Exception as ex:\n",
        "        result = f\"FAILED to create index: {ex}\"\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This function returns the current status for the search index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5OGmcuaaKF75"
      },
      "outputs": [],
      "source": [
        "def get_index_status():\n",
        "  info = r.ft(\"idx:vecdoc\").info()\n",
        "  return info"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This function inserts one document in Redis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bt_wqC2yKM3Y"
      },
      "outputs": [],
      "source": [
        "def write_vector(document):\n",
        "    result = \"FAILED\"\n",
        "    try:\n",
        "        pipeline = r.pipeline()\n",
        "        redis_key = document['id']\n",
        "        pipeline.json().set(redis_key, \"$\", document)\n",
        "        res = pipeline.execute()\n",
        "        result = f\"{redis_key} record inserted successfully\"\n",
        "    except Exception as e:\n",
        "        result = f\"FAILED with error: {e}\"\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This function performs a vector search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def vector_query(query_vector):\n",
        "    response = \"FAILED TO RUN QUERY\"\n",
        "\n",
        "    query = (\n",
        "        Query('(*)=>[KNN 3 @vector $query_vector AS vector_score]')\n",
        "        .sort_by('vector_score')\n",
        "        .return_fields('vector_score', 'name', 'filename', 'type', 'color', 'marketing_description')\n",
        "        .dialect(2)\n",
        "    )\n",
        "    query_input = query_vector\n",
        "    query_response = r.ft(\"idx:vecdoc\").search(query, { 'query_vector': np.array(query_input, dtype=np.float32).tobytes() }).docs\n",
        "    response = []\n",
        "    for doc in query_response:\n",
        "        response.append(doc)\n",
        "    return response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This function performs a hybrid search, by vector and metadata (in this case, color)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def vector_query_by_color(query_vector, color):\n",
        "    response = \"FAILED TO RUN QUERY\"\n",
        "\n",
        "    query = (\n",
        "        Query('(@color:$color)=>[KNN 3 @vector $query_vector AS vector_score]')\n",
        "        .sort_by('vector_score')\n",
        "        .return_fields('vector_score', 'name', 'filename', 'type', 'color', 'marketing_description')\n",
        "        .dialect(2)\n",
        "    )\n",
        "    query_input = query_vector\n",
        "    query_response = r.ft(\"idx:vecdoc\").search(query, {'color': color,'query_vector': np.array(query_input, dtype=np.float32).tobytes() }).docs\n",
        "    response = []\n",
        "    for doc in query_response:\n",
        "        response.append(doc)\n",
        "    return response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfgHUnJx7EqP"
      },
      "source": [
        "### Save Vectors to Redis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ChKJ5TivKWeA"
      },
      "outputs": [],
      "source": [
        "insert_results = []\n",
        "try:\n",
        "    create_index(1024)\n",
        "except Exception as e:\n",
        "    print(f\"Failed to create index with exception: {e}\")\n",
        "    insert_results.append(e)\n",
        "\n",
        "for i in range(len(vector_documents)):\n",
        "    document = vector_documents[i]\n",
        "    insert_result = write_vector(document)\n",
        "    insert_results.append(insert_result)\n",
        "    if i % 5 == 0:\n",
        "        print(f\"--> Inserting document {i} - result: {insert_result}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cs9QcQN97I_g"
      },
      "source": [
        "Check Index status (it should display the number of documents inserted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jBHp5BiHKjIp"
      },
      "outputs": [],
      "source": [
        "index_status = get_index_status()\n",
        "print(f\"Name: {index_status['index_name']} | Docs: {index_status['num_docs']} | Errors: {index_status['Index Errors'][0].decode()}:{index_status['Index Errors'][1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6oBBqwS7haw"
      },
      "source": [
        "&nbsp;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJakv8xO7i8Q"
      },
      "source": [
        "<img src=\"https://github.com/denisabrantesredis/denisd-GenAI-Workshop/blob/main/_assets/images/callout_insight.png?raw=true\" alt=\"Callout - Check Redis Insight\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hp36z0d-7hR7"
      },
      "source": [
        "The image vectors, along with their metadata, should not be visible in Redis Insight.\n",
        "\n",
        "You can also go to the **Workbench** and get a list of indexes using the command:\n",
        "\n",
        "```\n",
        "FT._list\n",
        "```\n",
        "\n",
        "Finally, you can get more details about the index that was automatically generated by Langchain with this command:\n",
        "```\n",
        "FT.info \"idx:vecdoc\"\n",
        "```\n",
        "&nbsp;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbNoHMtFN45X"
      },
      "source": [
        "## Part 5 - Running a Semantic Search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwR5FEo2AJjK"
      },
      "source": [
        "Redis supports Semantic caching and searching not only for text, but also image and other types of vectors.\n",
        "\n",
        "First, we will take a look at the images we can use for search; these images were not in the dataset that was stored as vectors in Redis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFuDm3vwOCJg"
      },
      "outputs": [],
      "source": [
        "test_images = glob.glob(\"./img_search_20/*\")\n",
        "len(test_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15, 5))\n",
        "for i in range(len(test_images)):\n",
        "    image_path = test_images[i]\n",
        "\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "    plt.subplot(4, 5, i+1)\n",
        "    plt.imshow(image)\n",
        "    label = f\"{i}\\n{image_path}\"\n",
        "    plt.xlabel(label, fontsize=8)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tv75yqFrAqry"
      },
      "source": [
        "<img src=\"https://github.com/denisabrantesredis/denisd-GenAI-Workshop/blob/main/_assets/images/callout_threshold.png?raw=true\" alt=\"Callout - Semantic Threshold\"/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rA-yaqYtN-bR"
      },
      "outputs": [],
      "source": [
        "redis_cache = RedisSemanticCache(redis_url=REDIS_URL, embeddings=embeddings, distance_threshold=0.2)\n",
        "set_llm_cache(redis_cache)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pv6nR-AFBEVZ"
      },
      "source": [
        "Since the Semantic Cache is new, it will be empty. We will ask the original question first, to generate the cache entry:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bm3SLk2u-SWn"
      },
      "outputs": [],
      "source": [
        "query = \"How does Redis Insight make RDI simpler?\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjeCV10VBMD8"
      },
      "source": [
        "Prepare the prompt:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W3Pvy352-Rsb"
      },
      "outputs": [],
      "source": [
        "messages = get_system_template(text_list, query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWKkgnnoBO-d"
      },
      "source": [
        "Invoke the model (it will cause a cache miss):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YJGYVojmWUdB"
      },
      "outputs": [],
      "source": [
        "timer_start = time.perf_counter()\n",
        "llm_response = llm.invoke(messages)\n",
        "timer_end = time.perf_counter()\n",
        "total_time = round(timer_end - timer_start, 4)\n",
        "print(f\"Total Time: {total_time}s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--0PfUm1BUa8"
      },
      "source": [
        "Print the response:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "heR894L4-lHd"
      },
      "outputs": [],
      "source": [
        "llm_response.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNVN4Q2MBYOQ"
      },
      "source": [
        "&nbsp;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xoqlHw8DO0zL"
      },
      "source": [
        "<img src=\"https://github.com/denisabrantesredis/denisd-GenAI-Workshop/blob/main/_assets/images/callout_insight.png?raw=true\" alt=\"Callout - Check Redis Insight\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PoO1iZmVO1zW"
      },
      "source": [
        "A new Hash document will appear in Redis, with a key prefix of `llmcache`. This is the cached prompt, which includes the question and the answer. The `invoke` function will run a semantic search for these documents, to look for similar questions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDfgdGQnO_ci"
      },
      "source": [
        "&nbsp;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3iZspjDQc_b"
      },
      "source": [
        "#### Ask a similar question to trigger a cache hit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E1dac3x9QV-h"
      },
      "outputs": [],
      "source": [
        "query = \"What does Redis Insight do to make RDI simpler?\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5WV9CfJBedI"
      },
      "source": [
        "Prepare the prompt:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X6ekUthmQXVh"
      },
      "outputs": [],
      "source": [
        "messages = get_system_template(text_list, query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1Syj2_WBgTC"
      },
      "source": [
        "Invoke the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XNeUsew8QXSu"
      },
      "outputs": [],
      "source": [
        "timer_start = time.perf_counter()\n",
        "llm_response = llm.invoke(messages)\n",
        "timer_end = time.perf_counter()\n",
        "total_time = round(timer_end - timer_start, 4)\n",
        "print(f\"Total Time: {total_time}s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e78ba7Y5Bi66"
      },
      "source": [
        "Print the response:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tt_hlPsRQXQE"
      },
      "outputs": [],
      "source": [
        "llm_response.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAVzG-35N0JI"
      },
      "source": [
        "&nbsp;\n",
        "\n",
        "\n",
        "&nbsp;\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4G4eIa8hN2T9"
      },
      "source": [
        "# Congrats, this is the end of the lab!!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
